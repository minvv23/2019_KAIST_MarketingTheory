{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **What You See is What You Say : How Can Images Shape Online Trolling**\n",
    "## TaeYoung Kang (IT Management, KAIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The behavior and decision making of an agent is hugely affected by emotional state. (George and Dane, 2016) Among various types of emotions, *anger* is considered to be a catalyst for the attitude of evaluating others (Wiltermuth and Tiedens, 2011), and hence, the comments section on online news platform has been an ideal place to observe such relation. Since it provides affluent opportunities to handle the key concepts of social science including emotion, user interaction, and opinion formation, *online trolling and swearing effects* has been a main concern in computational social science and its adjacent fields. (Kwon and Gruzd, 2017; Ksiazek, 2018; Weber, 2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This research also aims on verifying the variables that could influence the *incivility level* of users based on online news platform comments data. The users' internal process of writing comments and reflecting their emotions through it is complicated. The negative sentiment level of news article's title and content would affect the users' comment at the first hand. At the same time, however, we should not neglect the effect of attached image, called *thumbnail*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *human salience level* in thumbnail image is a key concern of this research. According to previous research, the *numerical salience level*, or *the number of an object* tends to present a unique relationship with the emotion provoked from that object. (Hsee and Rottenstreich, 2004) Their relations are illustrated in the plot below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='/img/hsee_plot.png' width=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such pattern could give us a hint on interpretating the possible outcome of human salience. Reporters can adopt distinct thumbnail images even when dealing with the identical issue as they have different level of human salience. In case of news article on economic downturn for instance, the reporter can use either the picture of ministry of economy building, GDP time trend visualization plot, or the specific photo on the minister which is a concrete human figure. In sum, the percepted human salience level of image would show the relations below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a < b \\le c$  \n",
    "where  \n",
    "$a$ = image with no human figure  \n",
    "$b$ = image with a single human figure  \n",
    "$c$ = image with multiple human figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Attribution Theory* takes an important role as a theoretical base on the relations between online trolling and human feature salience. Social psychologists have argued that angry agents are prone to express their emotion more intensely when the source of the anger is provided, since it enables the attribution to that source. Such source salient circumstance is highly similar with online news platform environment. When positing the news commenters with an explicit political predisposition, they would be more likely to show harsher attitude to the article when the human feature is provided as a specific source in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside of theoretical issues, this research can also enrich the empirical analysis by adopting latest computer vision and natural language processing techniques. The angle, color, and aesthetic quality of an image is known to affect the customer's information acquirement and emotion formation (Hagtvedt, H., V.M. Patrick. 2008; Miller, E.G., B.E. Kahn. 2005; Larsen, V., D. Luna, L. A. Peracchio, 2004.). During past several years, deep neural network showed a drastical improvement and aided researchers by enabling the measurement of more complicated internal aspects of an image. (Zhang, Shunyuan, et al, 2016) Facial recognition is not an exception. Simply by adopting existing computer vision packages, verifying the location and size of human faces is an easy task these days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hypothesis, Measurement, and Research Design**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, this research aims on testing the hypothesis with the model below.\n",
    "  \n",
    "***Hypothesis :  \n",
    "The more salient the human features in the thumbnail image of an article, the higher the average swearing level of all the comments it has.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sum_{j=1}^{m} s_{i_{j}} = \\beta_1x_i + \\beta_2h_i + f(\\sum_{j=1}^{m} s_{i_{j,t-}}) + \\beta_3 \\sum_{j=1}^{m} d_{i_{j}} + \\beta_4 \\sum_{j=1}^{m} g_{i_{j}} + \\epsilon_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$s_{i_{j}}$ = incivility level of comment written by $j^{th}$ commenter of $i^{th}$ article  \n",
    "$x_i$ = control variables generated from $i^{th}$ article (ex. number of comments, topic sentiment, article sentiment, article length)  \n",
    "$h_i$ = human feature salience level of $i^{th}$ article's thumbnail image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$s_{i_{j,t-}}$ = incivility levels of ***previous comments*** written by $j^{th}$ commenter of $i^{th}$ article  \n",
    "$d_{i_j}$ = $j^{th}$ commenter of $i^{th}$ article's diversity of news consumption  \n",
    "$g_{i_j}$ = $j^{th}$ commenter of $i^{th}$ article's average time gap on writing new comment (= proxy variable for the acivity level of user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data and Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Daum*, the second largest local web portal of South Korea, has been running a news platform since 2012. Since Korean news media market is heavily dependent to web portals, analyzing the data from Daum News would be appropriate to test the hypothesis. From each articles, we scraped every accessible information including the (1)title, (2)content, (3)press name, (4)submission date, (5)entire comments, and (6)thumbnail image file. When analyzing the online data, however, we must be aware that the underlying selection bias could be a serious issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of *supply side*, or the writers, there would be a complex decision making process behind the selection of news topic, image, and contents so to attract more traffics from the readers. For the *demand side*, or the readers, their willingness to leave comments would differ based on each of their unique predispositions, and would hence lead to the biased exhibition of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='/img/daum_poli_topic.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='/img/example_topic.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='/img/example_comment.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='/img/example_history.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='/img/facial_recognition.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measurement of swearing comments, however, is a way more complex issue. As users are aware of dictionary based automatic swear words censoring algorithm, they try not to swear directly. In English, for example, users would type *\"$hit\"* or *\"5hit\"* instead of *\"Shit\"*. It becomes even more complicated when it comes to *Hangul*, the Korean alphabet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='/img/jamo.png' width=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, each character is composed of three subcharacters(or *jamo*) called *chosung(초성)*, *joongsung(중성)*, and *jongsung(종성)*. To convert these unique character system similar to latin alphabet, we can simply split character into consecutively listed subcharacters. (ex.해달→ㅎㅐㄷㅏㄹ)  (Park, Sungjoon et al, 2018) Although it hinders the human interpretability of words and models derived from them, its merits on word-vector embedding generation could exceed such trivial dimerit, especially when designing swear words classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adopting FastText, an algorithm which generates word-vector embeddings based on subcharacter n-grams (Bojanowski et al, 2016; Joulin et al, 2016), on *Hangul* subcharacter preprocessing trick, we can maximize the classification performance. Let's look at more specific swear example. *병신*, a common Korean swear word, can be variously modified into other forms such as *빙신*, *비융신*, *븅신*, *병싄*, *병1신*, and *븅1쒼*. If we use swear words dictionary, it would be hardly possible to detect the correlation between these variations. Such predicament would still not be alleviated when using POS(Part of Speech) tagged words, since there are almost infinite possibility to generate new variation simply by adding or substituting a single subcharacter. However, if we split subcharacters of words and then apply FasatText, the shared subcharacters and subsequent n-grams shared among these words such as *{ㅂ, ㅇ, ㅅ, ㅣ, ㄴ}*, *{ㅣㅇ, ㅇㅅ, ㅣㄴ}*, and *{ㅣㅇㅅ}* are now detected. When tested this methodology on pilot data, it showed intuitively enhanced performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_ㄱㅏㅣㅅㅏㅣdㄱㅣ', 0.9877994060516357),\n",
       " ('ㄱㅏㅣㅅㅏㅣdㄱㅣㄱ', 0.9872113466262817),\n",
       " ('ㄱㅏㅣㅅㅏㅣdㄱㅣㄴ', 0.9870151281356812),\n",
       " ('ㄱㅏㅣㅅㅏㅣdㄱㅣ_', 0.9867669343948364),\n",
       " ('ㅣㄱㅏㅣㅅㅏㅣdㄱㅣ', 0.9831262230873108),\n",
       " ('ㄱㅏㅣㅅㅏㅣdㄱㅣㅇ', 0.9806551933288574),\n",
       " ('ㅇㄱㅏㅣㅅㅏㅣdㄱㅣ', 0.9803736209869385),\n",
       " ('ㅏㅣㅅㅏㅣdㄱㅣㄱㅏ', 0.9734358787536621),\n",
       " ('ㄱㅏㅣdㅅㅏㅣdㄱㅣ', 0.973200798034668),\n",
       " ('ㅗㅏㅣㅈㅣㅅㅏㅣdㄱ', 0.9714223146438599)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftmodel.wv.most_similar(jamo_split('개새끼'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅏ_ㄱㅏㅣㅅㅏㅣㄱg', 0.984258234500885),\n",
       " ('ㅣ_ㄱㅏㅣㅅㅏㅣㄱg', 0.9773533940315247),\n",
       " ('ㅜ_ㄱㅏㅣㅅㅏㅣㄱg', 0.975597620010376),\n",
       " ('ㅅㅜ_ㄱㅏㅣㅅㅏㅣㄱ', 0.9745869040489197),\n",
       " ('ㄱㅏㅣㅅㅣㅂㅅㅏㅣㄱ', 0.970960259437561),\n",
       " ('ㄱㅏㅣㅅㅏㅣㄱㅎㅣㄷ', 0.9684487581253052),\n",
       " ('ㅗㅏㅣㅈㅣㅅㅏㅣㄱg', 0.9662880301475525),\n",
       " ('ㄷㅗㅏㅣㅈㅣㅅㅏㅣㄱ', 0.9652479887008667),\n",
       " ('_ㄱㅏㅣㅅㅏㅣㄱgㄱ', 0.9650763273239136),\n",
       " ('ㄴ_ㄱㅏㅣㅅㅏㅣㄱg', 0.9591826796531677)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftmodel.wv.most_similar(jamo_split('갯1쉭키'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
